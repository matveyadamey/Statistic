
>[!seealso] **Лемма**
>>[!Quote]   ****
>Функция $pdf(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ при любых $\mu$ и $\sigma^2 > 0$ задаёт корректную плотность


>[!def] **Определение**
>>[!Quote]   **Нормальное распределение со средним $\mu$ и дисперсией $\sigma^2$**
> — это непрерывное распределение с плотностью
> $$pdf(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$
> Обозначается $\mathcal{N}(\mu,\sigma^2)$
> Носитель - $\mathbb{R}$

![[norm.png]]

В Python:
```Python
sps.norm(mu,sigma)
```
 где sigma - стандартное отклонение


>[!seealso] **Лемма**
>>[!Quote]   **Линейная комбинация двух независимых нормальных величин**
>>Если $X$, $Y$ — независимые и нормально распределённые случайные величины, $a, b \in \mathbb{R}$ — числовые коэффициенты, причём хотя бы один коэффициент ненулевой, то:
>>1. $aX + bY$ распределена нормально;
>>2. $\mathbb{E}(aX + bY) = a \cdot \mathbb{E}X + b \cdot \mathbb{E}Y$;
>>3. $\mathbb{V}(aX + bY) = a^2 \cdot \mathbb{V}X + b^2 \cdot \mathbb{V}Y$.
Математически можно записать:
>>$$
aX + bY \sim \mathcal{N}(a\mathbb{E}X + b\mathbb{E}Y,\ a^2\mathbb{V}X + b^2\mathbb{V}Y)
>>$$


>[!seealso] **Лемма**
>>[!Quote]   **Сумма и среднее арифметическое выборки из нормального распределения**
>>Если $X_1, X_2, \dots, X_n$ — случайная выборка из нормального распределения $\mathcal{N}(\mathbb{E}X,\ \mathbb{V}X)$, то
>>$$
\sum_{i=1}^{n} X_i \sim \mathcal{N}\left(n\mathbb{E}X,\ n\mathbb{V}X\right)
>>$$
>>$$
\overline{X} \sim \mathcal{N}\left(\mathbb{E}X,\ \frac{\mathbb{V}X}{n}\right)
>>$$


>[!seealso] **Лемма**
>>[!Quote]   **Симметрия нормального распределения**
>>$$P(X \leq \mu - h) = P(X \geq \mu + h)$$
>$$pdf(\mu+h)=pdf(\mu-h),\quad \forall h$$
>$$CDF(\mu +h)+CDF(\mu-h)=1, \quad \forall h$$


## Правило 3 сигм

>[!seealso] **Лемма**
>>[!Quote]   **Правило трех сигм**
>Пусть $X \sim \mathcal{N}(\mu, \sigma^2)$
>Тогда $$P(\mu-3\sigma \leq X \leq \mu+3\sigma)=0.9973$$


>[!seealso] **Лемма**
>>[!Quote]   **Правило 68-95-99.7**
>>- В пределах $1\sigma$ - около 68% значений
>>- В пределах $2\sigma$ - около 95% значений
>>- В пределах $3\sigma$ - около 99.7% значений

### Приближение колоколообразного распределения нормальным

![[bin norm.png]]

Матожидание - вершина графика
Выделяем промежуток, который содержит почти 100% вероятности
Считаем его длину и вычисляем стандартное отклонение

>[!attention] Важно
>Не все колоколообразные распределения можно аппроксимировать нормальным:
>- Асимметричные (скошенные) — нет
>- С тяжёлыми хвостами — осторожно
>- Дискретные (например, биномиальное при малых nn или pp далеко от 0.5) — могут плохо приближаться


## Стандартное нормальное распределение

>[!def] **Определение**
>>[!Quote]   **Стандартное нормальное распределение**
> $$\mathcal{N}(0,1)$$

Обозначения:
- $Z \sim \mathcal{N}(0,1)$
- $\Phi=CDF_Z$
- $\phi = pdf_Z$
- $Z_\alpha=PPF_Z(a)$

>[!seealso] **Лемма**
>>[!Quote]   **Приведение произвольного нормального распределения к стандартному**
>Если $X \sim \mathcal{N}(\mathbb{E}X,\mathbb{V}X)$,то
>$$\frac{X-\mathbb{E}X}{\sqrt{\mathbb{V}X}} \sim\mathcal{N}(0,1)$$

Это преобразование называется **стандартизацией**, а результат — **стандартной нормальной величиной Z**.

>[!seealso] **Лемма**
>>[!Quote]   **Связь произвольного и стандартного нормального распределения**
>>$CDF_{\mathcal{N}(\mu,\sigma^2)}(a)=\Phi(\frac{a-\mu}{\sigma})$
$PPF_{\mathcal{N}(\mu,\sigma^2)}(a)=\mu+\sigma \cdot z_\alpha$

## Z-score

>[!def] **Определение**
>>[!Quote]   **Z-score числа а относительно $\mathcal{N}(\mu,\sigma^2)$**
> $$\frac{a-\mu}{\sigma}$$

>[!hint] **Интерпретация**
>Показывает, на сколько стандартных отклонений значение a больше матождидания

>[!example] **Пример**
> Рост человека: X=180см, μ=170, σ=5
> $z=\frac{180-170}{5}=2$→ рост на 2 стандартных отклонения выше среднего.


[[Распределение хи-квадрат]]
[[Распределение Стьюдента]]
